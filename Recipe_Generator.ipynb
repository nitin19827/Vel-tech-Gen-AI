{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZE/LtL1XMog2g1QlHIGVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitin19827/Vel-tech-Gen-AI/blob/main/Recipe_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbDCnQfgngK",
        "outputId": "7853cb0e-e45e-4e6b-a17c-4c4f55ec29d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import FlaxAutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"flax-community/t5-recipe-generation\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH, use_fast=True)\n",
        "model = FlaxAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "\n",
        "prefix = \"items: \"\n",
        "generation_kwargs = {\n",
        "    \"max_length\": 512,\n",
        "    \"min_length\": 64,\n",
        "    \"no_repeat_ngram_size\": 3,\n",
        "    \"do_sample\": True,\n",
        "    \"top_k\": 60,\n",
        "    \"top_p\": 0.95\n",
        "}\n",
        "\n",
        "\n",
        "special_tokens = tokenizer.all_special_tokens\n",
        "tokens_map = {\n",
        "    \"<sep>\": \"--\",\n",
        "    \"<section>\": \"\\n\"\n",
        "}\n",
        "def skip_special_tokens(text, special_tokens):\n",
        "    for token in special_tokens:\n",
        "        text = text.replace(token, \"\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def target_postprocessing(texts, special_tokens):\n",
        "    if not isinstance(texts, list):\n",
        "        texts = [texts]\n",
        "\n",
        "    new_texts = []\n",
        "    for text in texts:\n",
        "        text = skip_special_tokens(text, special_tokens)\n",
        "\n",
        "        for k, v in tokens_map.items():\n",
        "            text = text.replace(k, v)\n",
        "\n",
        "        new_texts.append(text)\n",
        "\n",
        "    return new_texts\n",
        "\n",
        "def generation_function(texts):\n",
        "    _inputs = texts if isinstance(texts, list) else [texts]\n",
        "    inputs = [prefix + inp for inp in _inputs]\n",
        "    inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"jax\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs.input_ids\n",
        "    attention_mask = inputs.attention_mask\n",
        "\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        **generation_kwargs\n",
        "    )\n",
        "    generated = output_ids.sequences\n",
        "    generated_recipe = target_postprocessing(\n",
        "        tokenizer.batch_decode(generated, skip_special_tokens=False),\n",
        "        special_tokens\n",
        "    )\n",
        "    return generated_recipe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "1fda008156274174ac06f624e58d4ee0",
            "5dbd9364411f499c84327ad948c2542f",
            "9eb2c6cd2faa48baa6021554b7080361",
            "2801fb86ca2c46929fb2562d0c4c908e",
            "7df1c1796e5842e1bb8cb5a94a64d659",
            "0dd7e0f3389b4e7f8e0237a402246db7",
            "61b8de79e95743dcb22d64ccb7a598cd",
            "0866100ff045427594a3db8fbc5cb955",
            "1c57670eebad4bb984dc0f496534c0f5",
            "cefa975bc74a47bdb33199a2b7971f93",
            "f0076b3c3fc64315b17615bde8709068",
            "834338af8da44d1fb92f3928e15b38e6",
            "d47dc80fbca9400bbbaadedb12732cf2",
            "ff06ce6a32754c0d8acfa6e815daaeac",
            "d1e5125ba3014ae5a075295234c53034",
            "d05a32b0da63457c877b542c6757b74e",
            "8e6eb44ca3184b6e8d83ca11183fa38a",
            "bb5d69b44ff648dbbc0b104cc8fef1d0",
            "d6ceda34ac64453585d64a2d7717b1fb",
            "edf8b1374ac8463b8c85a21ffe0297fb",
            "4561a479ebb24230abd0f7233942e199",
            "4d34634c34c1463aaf9765cbaab67e96",
            "e0576d983e2847458f81df39290e4ec9",
            "1bd1b7c84be74934a7b842d45ff974b6",
            "c8c317cb4df541a6bc1d04f01131ee82",
            "8c36a135cd614696a9fc4a211591b5f8",
            "5701b9fc941448af804aecaa09d03d30",
            "c7ce48615a3d4d4284a1aa8e46fe3f1e",
            "f70c4a455c4444b193f9133a7f19c7e5",
            "0109b177bdde4d51af7f23f52cb6c53c",
            "6dcc2121121f4e98a6229c92c85b0fa7",
            "c9d4289602ab45068a343f5b4fb60e33",
            "a702e9c618b74823aa05d7e082bc3551",
            "bfed91887fa1483486114dc3d57b7a18",
            "07b98eda2d804636acf5dc8ff13b1297",
            "e4545caa9589497a8ef9ac0598695b2c",
            "976e4cf2464f45c0b233940d4ae1d312",
            "7542c789b4a447678465234736cec0e5",
            "79dd1b99d7334b73b68443c4faffa180",
            "47f0c9b0f39549e490f3e0043ca08567",
            "b1c2b8cef1df4849af1a68ffde6fdada",
            "ed61da2f27304605b225b661d8ef7a6e",
            "e6986f7fa5c24586aa389934cf6185e1",
            "4c0fca4049704ef792a9418594a0ea46",
            "dc410dfbf43245cf8d419bb4eb861b83",
            "e8e21cce2ab14fbea12e8eeb95b61a78",
            "ba406945a84c47ac98c95d18b5479a7b",
            "b4308ead21044fae93459fe14fbc560f",
            "c687a1ff90ea4e48a22b612c3fd88e2d",
            "7480fe6e1819475fb323c2650e8b0066",
            "f3c9629456bf4272a94251e4bc31e286",
            "375f7a7e1627487989d8bf70d09d5b9b",
            "dd2d24ca5d314b24a8151b44418f0b6a",
            "e3d441064e784c828b01f773aaaba966",
            "7a8709b4228d49a589655973f0fab5da"
          ]
        },
        "id": "23PwHXLdg58N",
        "outputId": "38c9b93d-09b6-43ca-ae25-2f68bb29e3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fda008156274174ac06f624e58d4ee0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "834338af8da44d1fb92f3928e15b38e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0576d983e2847458f81df39290e4ec9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfed91887fa1483486114dc3d57b7a18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "flax_model.msgpack:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc410dfbf43245cf8d419bb4eb861b83"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = [\n",
        "    \"egg, tomato, bread\"\n",
        "]\n",
        "generated = generation_function(items)\n",
        "for text in generated:\n",
        "    sections = text.split(\"\\n\")\n",
        "    for section in sections:\n",
        "        section = section.strip()\n",
        "        if section.startswith(\"title:\"):\n",
        "            section = section.replace(\"title:\", \"\")\n",
        "            headline = \"TITLE\"\n",
        "        elif section.startswith(\"ingredients:\"):\n",
        "            section = section.replace(\"ingredients:\", \"\")\n",
        "            headline = \"INGREDIENTS\"\n",
        "        elif section.startswith(\"directions:\"):\n",
        "            section = section.replace(\"directions:\", \"\")\n",
        "            headline = \"DIRECTIONS\"\n",
        "\n",
        "        if headline == \"TITLE\":\n",
        "            print(f\"[{headline}]: {section.strip().capitalize()}\")\n",
        "        else:\n",
        "            section_info = [f\"  - {i+1}: {info.strip().capitalize()}\" for i, info in enumerate(section.split(\"--\"))]\n",
        "            print(f\"[{headline}]:\")\n",
        "            print(\"\\n\".join(section_info))\n",
        "\n",
        "    print(\"-\" * 130)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6BCxTd3hCf1",
        "outputId": "0d6c1ae9-f1f1-4256-cccf-a740480548e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TITLE]: Quick breakfast burger\n",
            "[INGREDIENTS]:\n",
            "  - 1: 1 egg\n",
            "  - 2: 1 tomato\n",
            "  - 3: 2 slice bread\n",
            "[DIRECTIONS]:\n",
            "  - 1: Turn oven on 450\n",
            "  - 2: Crack egg in to glass measuring cup and fill with water, about 3/4 the way up the glass.\n",
            "  - 3: Let stand in the egg wash for 10 to 15 minutes.\n",
            "  - 4: Using a 2 inch biscuit cutter or sharp knife, cut the biscuits in to round pieces.\n",
            "  - 5: Then, cut a 1/4 inch wide hole in the middle of each biscuit and carefully stuff each biscuit with 1 or 2 tomato slices.\n",
            "  - 6: Make sure not to overcrowd the biscuit cutter.\n",
            "  - 7: Place the muffin tin on a cookie sheet and place the tinfoil on top of each muffin.\n",
            "  - 8: Put in the oven for 7 minutes.\n",
            "----------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}