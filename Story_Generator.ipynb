{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JeqSUo6gYccaDAF-oDfGYK25_3pF9aoK",
      "authorship_tag": "ABX9TyMA/N5p2thke6bPOFl66rud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitin19827/Vel-tech-Gen-AI/blob/main/Story_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "194a1b23f70544599b1eba1577ac5960",
            "a8f54db66f594a7095760d704b5421c5",
            "8f63eec43f9c440c986b4bc97752a6eb",
            "260f0328f02148ff987b229375ed8a11",
            "8dc1747edbf4474f8a4bb8808810b31b",
            "aea4252262c84b5380d0dc064ca281a9",
            "27a0fd1f22bf4aea920538368ece3dc2",
            "08776b66c7b64ad8a002bc301a46a416",
            "573a7030822642bab8728fe67cb47c8d",
            "e2a612c704584b6c939a188fdd200d98",
            "bfa34a3c408c4383ae8d7663c9e93981",
            "126a5fbf5da84dcd821b8acc38a3d0be",
            "4239fa412d124b7cbad0b1ae56f8c935",
            "f36cda573a49455a8f660d8b98ef4744",
            "4020183ce3504735b70f8abb4de60454",
            "19ec4a018da741b496e3f806d5478bcf",
            "5d4ef5d4ada3400796bee0d3e5a8c751",
            "b28d117a466f4929971061ad3d87112b",
            "a7caf3d18da44b928d0db66ad48977e8",
            "6dea4eae69224c908b719d4e5c52a25a",
            "9fac7ec9a7134484bbc1989f1b4a1bbb",
            "34419f7b65a44cab95418eb61f49cc6d",
            "bc10bd3b65784052ba7544e19c67a700",
            "9b64bd04a02f4b49accec41810ee832f",
            "33039f3df97d4f878f1a4dfba9884d3a",
            "207852eaa9244dbea4192b7b71a00cee",
            "b3dfbd14623f4d6f915cb6ecbaf65c9e",
            "0f0bfee6a97e4a2b82d7c19a48a4ab6a",
            "32c8f06ac5164571817d5452f7b46d3f",
            "c0c1debcd42a4927bea86f8abde94ee0",
            "678d3479bfbb4eb9a0fef9618af6865c",
            "f3cc4dd789e340c39a2daf2f4eec5032",
            "bd819409196640e1adbdd3c5d03da64f",
            "5aea6b5fd27444db91d3c562151c8c48",
            "6a43cbef06a340818d5d10d1462b93b3",
            "9b554d75c9aa4bc3a46f296a03a29e43",
            "2088ae3d729e4e8ebee5d3603ff25c0b",
            "8726378b12234f938f713a11bbb64802",
            "a6e57f15e1e842e59817287e2b40da99",
            "1a4cbff364704630b0d6246acee38ffd",
            "14b8291cbc0d482289a13ed1b1216873",
            "b04eac35caba4767b58a2d676ef410a3",
            "b46ed5b51ea548ebbc9e873ecdf89965",
            "0303f0fdac7c48768503a315b1dfa65b",
            "952a5a93ca844fdc90d4689e76aa469a",
            "43e66bc4c56e4995a72d03c87abf3be5",
            "fd53a322904e4d8aac8778d0b8535715",
            "616db0f877dd4dc8acaa6ebfd29aaba2",
            "0e9262eb4c66480bb343392cd03b594d",
            "d77d69ce09ae488b8263c387c184d923",
            "a1afa53a7b304e88a7f54abf52fc4b6e",
            "c85240e9ce8b4f1b9246f080396ef461",
            "48761f08e23742b1802f82214ae21703",
            "b351da2cffcf4b58afe2cdcb384c7653",
            "c08088c79c77428c86a68c1513877255",
            "4dd3072c49f94d3c87c072f43fa33727",
            "84015799d31f48a19a24ef6ef7d07e51",
            "21110cb433384f1dafd91f75b6eff925",
            "559136b3e4914c2ca1f14da49a21897a",
            "8b47c6c79bb542b98f47c2fef3838c75",
            "dd8b546ee0fb4f30862f9eee29266dd8",
            "05936103857f4113b9848e6657459283",
            "a31fc34df2764dc483c425478d13c39f",
            "652862bc1287495aa77afb7169c4cf15",
            "6be4f24138234b4d9b27b09c73dbf53f",
            "e0f68e858f5c4066a7d797a1713cdf77",
            "78714e20ae964663ad6c6c4cae3eb154",
            "83ab2b901f6841e9aa17ab545f935439",
            "4491d0d604f7423c8a7edabc3a0d9ed9",
            "2d3b3241ae6841cb9b1794e2b2c77d37",
            "655b0fa73cdb4704bfd8ed154e7bbcc6",
            "65c7dcf567604da3ab92be2cfcfd5b95",
            "c08192671c7f46a7a3e57243f50c46dc",
            "5cf0612701e244c085225306bbbd5316",
            "4bedc6a03cf743c58eb75fb4e636ef6b",
            "94ef1a3f7e44407fbac4551ea0998bc4",
            "a844f8a20ad24177b53db1f2b1f9abe4"
          ]
        },
        "id": "ZHKPA11ZfTKc",
        "outputId": "24f97f33-1fcf-4b36-989a-3b1c21c2d785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "194a1b23f70544599b1eba1577ac5960"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "126a5fbf5da84dcd821b8acc38a3d0be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc10bd3b65784052ba7544e19c67a700"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aea6b5fd27444db91d3c562151c8c48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "952a5a93ca844fdc90d4689e76aa469a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dd3072c49f94d3c87c072f43fa33727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/203 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78714e20ae964663ad6c6c4cae3eb154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': '<BOS> <superhero> Batman: Year of Sin is set during the Age of Sin. Sin is ruled by King Sinondros, who is facing two plots against the world: the evil forces of corruption in the arts, and those elements of the human race'}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "story_gen = pipeline(\"text-generation\", \"pranavpsv/gpt2-genre-story-generator\")\n",
        "print(story_gen(\"<BOS> <superhero> Batman\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, TextGenerationPipeline, GPT2LMHeadModel, AutoTokenizer\n",
        "model_name = \"aspis/gpt2-genre-story-generation\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "generator = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
        "# Input should be of format \"<BOS> <Genre token> Optional starter text\"\n",
        "input_prompt = \"<BOS> <adventure with two friends>\"\n",
        "story = generator(input_prompt, max_length=80, do_sample=True,\n",
        "               repetition_penalty=1.5, temperature=1.2,\n",
        "               top_p=0.95, top_k=50)\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcWi0BaPlFf8",
        "outputId": "831a94a4-0cad-4d99-8ea4-9768643d226d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': '<BOS> <adventure with two friends>  Kaejin stared at him. \"I\\'ve found her a way.\" I was stunned by his reaction when we started talking and he continued, just like that: \\'Yes,\\' however...\\' Then the light turned yellow to take us all back! After my surprise about that statement came over me feeling weak-forgetful again I couldn\\'t think'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"Tincando/fiction_story_generator\")\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"Tincando/fiction_story_generator\")\n",
        "\n",
        "# Generate a fiction story\n",
        "input_prompt = \"[WP] I can't believe I died the same way twice.\"\n",
        "input_ids = tokenizer(input_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "output = model.generate(input_ids,\n",
        "        max_length=300,\n",
        "        temperature=0.9,\n",
        "        top_k=2,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.2,\n",
        "        do_sample=True,\n",
        "        num_return_sequences=2\n",
        ")\n",
        "\n",
        "generated_story = tokenizer.batch_decode(output,clean_up_tokenization_spaces=True)[0]\n",
        "print(generated_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "8c09d90adade448fa3d1d9504a74a71f",
            "5e384376f20f4c978d2b29f9fb182cbf",
            "fee6636600274e8bb9791206e361b3a5",
            "da6fa541b27a44eba941a43a23871c67",
            "1202b0e418ee43fba133da39d38ce613",
            "136036df15184a018b8b52b3057a6c62",
            "fbd13bdafd844476b3c7eaabf58131f6",
            "c8de12474d784fd98319fe1bc0e3bd6f",
            "7f2a577c82d64bb79db1800556b0c51e",
            "b101e071112c452fa24db6441864028e",
            "44a5e383bb92469a9f01c4cd4ec27a4c",
            "20aa01d7fcb84dffaa77a5fdc8f12e2e",
            "40f909374c934f5a96229452b168ab6d",
            "2a244292fe4040c19fa320f5c1d97403",
            "ffc9cdee31df4371872c2d83e57c8b71",
            "26234dfa9d044f2694d8284fc4a722f8",
            "dace5c14ec1f4a9aaf11575819927e01",
            "3d3b0266d6444f25bdcfdf97cde7083b",
            "3e0deda26faf47d8a271c7463f57f8ce",
            "5cfec3bd64a247a59efe2dfdfb6fa75f",
            "eca3025b823a4833b31e46671b77447c",
            "40dd7de0936d4536813f94612211b7aa",
            "1cc9f599619342718460a50828c3eeb7",
            "16ac4f542d9842739a88e4af5cabbe85",
            "12b11759eccd4d328ac9fe19050694d5",
            "601d29fa4fb64753886cf7d5e9310d78",
            "8bec35bad76a452ebaf2be95abc12511",
            "3507dff13e4a4516b8c76fbd1a46f989",
            "9e043fa56a7f444e9dbca435d6e40bab",
            "22dcc95f04d041b4acd7ec0afc62facc",
            "646b63aa103941d6993ee47c08161cc5",
            "9fb4d1b64b38469697f3dbdd6ca31807",
            "74f01e96a0ca4c0c9acb8ed97e0e507a",
            "92370656364c4204af1e8dbf77e86c34",
            "331127ee53db4eb2a6637a7504e4f9bd",
            "1cab85517cfe4d509066e44e92f81509",
            "68a35fe126b74667a4a1513926fee6d2",
            "31253a169007436281e6b8352c2c7a68",
            "2e7db6c1265149d2b1dba40ba5959d56",
            "375876d396db4c0bafb1b65c871a9981",
            "5be99f28a59d448999b952c0f942abeb",
            "078db9dc43204dd4ac242f446cbd45f8",
            "f12aa7373e5347bc8dd18360adce8157",
            "d1606f6b496d4e0ab71a21366646d911",
            "ea9098a0b7b24981bfe6123e26650966",
            "c1eb4e276f334b51b021bc855875a1d6",
            "bbd1463466ec42cfbb36cec62e168935",
            "66e06a1ea7fc4004a80052f1ffe8dc07",
            "e83e09df13ed4f40815d72fdeff329e2",
            "f5a4530510bb4d3aafdd1f19037fdafa",
            "c3a7f206f2f5454ca73af53912a0dc40",
            "5d9774b7a80842ffa90e776a5009c2c4",
            "65b74686b5544c7586cb240a318783bf",
            "17adb3d2aeb84fdeb9de8c37d970bc8b",
            "39a53eac0d9e46ec9d2d6e3449db613d",
            "0a39802ab8764ee2905673fe45b2f2fd",
            "e8502ea6a2034b22b219b94865d3258b",
            "a75d0d9d9cbd4726afe54cca255d7fff",
            "20d02672c3db4ee5ae1841980ef96175",
            "736ebbbd2ba74329a17f10f5ed76a5e6",
            "9b765df70e434262892452194bccbb8e",
            "efead53be3c04626b35f0fec7a5f4d3a",
            "3fa7c9c2e6784224b38ab9cb0306de19",
            "76f11f0d37054b36854bc6fdf236cdfe",
            "0d329a13c835490c91501f50f19e1858",
            "ad812bc52ee14cd19264bdb6f6c053af",
            "5727103fc58643d1b99f5f51f3517bf1",
            "9062f531c5774e0fb4b92745aab02cea",
            "5fe3b040400946b3b4515936d2188274",
            "3c63e6daddcd4527a1226d45854837bf",
            "704a0e6288b54497904cd3563159a764",
            "6598932fecbd4c57bd377dd8cf10cf75",
            "ae62ea3fd8b548228ae720ee991d8c52",
            "5776dcbe88ac437887a5e5121802e8a1",
            "b98d289ad0bd49a2876e0a6fba27461f",
            "f9dadf6edf574885b15403aa9b451292",
            "fad164389f534d12b362348dfce9a532"
          ]
        },
        "id": "AgXuEoBdmHLo",
        "outputId": "605e5d21-2801-4c21-e68d-93451f51ba38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c09d90adade448fa3d1d9504a74a71f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20aa01d7fcb84dffaa77a5fdc8f12e2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc9f599619342718460a50828c3eeb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/470 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92370656364c4204af1e8dbf77e86c34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea9098a0b7b24981bfe6123e26650966"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a39802ab8764ee2905673fe45b2f2fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5727103fc58643d1b99f5f51f3517bf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WP] I can't believe I died the same way twice. Once in a blue moon and once in a red one, and I was there. <sep> `` You're dead! '' \n",
            " \n",
            " It's the only thing that makes sense. The last thing I remember was the first time I saw my wife, and I was there. \n",
            " \n",
            " She was beautiful. Her hair was long and brown, her skin a deep blue, her eyes a deep hazel. Her smile was infectious, and I loved her for it. But she wasn't the kind of person to be happy about anything. \n",
            " \n",
            " When I was a kid, I would play with my brother, and he would always say, `` Don't worry, you're going to get it over with. '' \n",
            " \n",
            " And I 'd laugh at him. He 'd laugh back. We 'd go to school together, and he 'd tell me stories of his life. Stories of how he 'd lived through the world, how he 'd been a great father, a great husband, a great friend. How he 'd lived his life, and how he 'd lived his death, and how he 'd lived the rest of his life, and how he 'd lived his life. \n",
            " \n",
            " Then, when I was a teenager, I 'd go to the movies and see the world. I would watch the world from my window\n"
          ]
        }
      ]
    }
  ]
}